{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CAB420, Practical 3 - Question 1 - Template\n",
    "\n",
    "## Binary Classification\n",
    "\n",
    "Consider the data set redwine-binary.csv. This data contains both objective measurements on chemical and physical properties of the red wines, and subjective measurements of quality based on expert judegments. In this data, wine quality is the response variable and is either \"above average\" (1) or \"below average\" (0) Using this data set:\n",
    "\n",
    "1. Fit a Support Vector Machine to the data, and select appropriate values of C and an appropriate kernel to maximise accuracy. \n",
    "\n",
    "2. Fit a K-Nearest Neighbours Classifier to the data, and select appropriate values of K and the distance metric to maximise accuracy.\n",
    "\n",
    "For both models, repeat your experiments with and without standardising the data, and note any differences in performance. \n",
    "\n",
    "### Relevant Examples\n",
    "\n",
    "The first classification example, ``CAB420_Classification_Example_1_Classification_Three_Ways.ipynb`` is a useful starting point here, as that also deals with binary classification.\n",
    "\n",
    "You may also find ``CAB420_Classification_Additional_Example_Classifier_Parameters_and_Decision_Boundaries.ipynb`` useful if you are uncertain on what impacts hyper-parameters have on performance. Finally, if you want to explore different measures of performance, ``CAB420_Classification_Example_3_Classification_Metrics.ipynb`` will be worth a look.\n",
    "\n",
    "### Suggested Packages\n",
    "\n",
    "We're leaning on sklearn fairly heavily here. The following imports will give you all you need (and then some), and follow the lecture examples. You are obviously free to use other packages however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# import important packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Loading and Splitting\n",
    "\n",
    "Here you need to:\n",
    "* Load the data, I'd suggest pandas and ``read_csv()`` as we've uesd elsewhere\n",
    "* Pull out X and Y data. Your Y values are the ``quality`` data series\n",
    "* Split the data into train and test. I'd suggest ``train_test_split`` from ``sklearn.model_selection``, which will split the data into two sets (i.e. split all data into train and test). If you wish to get three datasets (train, validation, and test), then:\n",
    "  * Split the data into train and \"the rest\", using say a 70/30 split\n",
    "  * Split \"the rest\" into validation and test, using a 50/50 split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Standardisation\n",
    "\n",
    "To standardise, or not to standardise?\n",
    "\n",
    "Use a box plot to visualise the scale of the different dimensions in the X data. Focus on the training set. The question asks you to explore performance both with and without standardisation, which you can do simply by commenting out standardistaion code which could go about here.\n",
    "\n",
    "Remember with your standardisation, you should compute the mean and standard deviation on the training set, and then use that mean and standard deviation to standardise your training, (validation? if you have it,) and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fitting Models\n",
    "\n",
    "Here you need to:\n",
    "* Fit an SVM, and explore parameter choices. In particular focus on what happens as you change C, the kernel, and kernel parameters ($\\gamma$ with an RBF kernel, the polynomial order with a polynomial kernal). Parameter choices can be explored either by:\n",
    "  * Simple trial and error\n",
    "  * A grid search, or similar automated search method. Look at ``CAB420_Classification_Example_1_Classification_Three_Ways.ipynb`` for an example of how to use such methods. More information is also available in the [sklearn documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
    "* Fit a CKNN, once again exploring parameter choices. In particular focus on K, and the distance measure chosen. You may also wish to experiment with the distance weighting scheme used. Again, either trial and error or a grid search (or similar) is a good choice here.\n",
    "\n",
    "An evaluation function is provided below, based on what is used in the lecture examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# helper function adapted from lecture examples\n",
    "\n",
    "# function to do our eval for us, this is quite simple and will\n",
    "# - create a figure\n",
    "# - draw a confusion matrix for the trainign data in a sub-fig on the left\n",
    "# - draw a confusion matrix for the testing data in a sub-fig on the right\n",
    "# - get precision, recall, f1 for test data\n",
    "# this has simply been created as we're going to do this for each test that we run\n",
    "def eval_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    fig = plt.figure(figsize=[25, 8])\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    conf = ConfusionMatrixDisplay.from_estimator(model, X_train, Y_train, normalize='true', ax=ax)\n",
    "    conf.ax_.set_title('Training Set Performance: %1.3f' % (sum(model.predict(X_train) == Y_train)/len(Y_train)));\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    conf = ConfusionMatrixDisplay.from_estimator(model, X_test, Y_test, normalize='true', ax=ax)\n",
    "    conf.ax_.set_title('Testing Set Performance: %1.3f' % (sum(model.predict(X_test) == Y_test)/len(Y_test)));\n",
    "    print(classification_report(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "name": "Untitled2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
